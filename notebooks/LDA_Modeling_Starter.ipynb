{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dea03a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import warnings\n",
    "import csv\n",
    "import os\n",
    "import nltk\n",
    "import pickle\n",
    "import sklearn\n",
    "import string, re\n",
    "import urllib\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from gensim import corpora, models\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "warnings.filterwarnings('ignore')\n",
    "#execute the following of not downloaded already:\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('stopwords')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk import FreqDist, word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from langdetect import detect_langs\n",
    "from langdetect.lang_detect_exception import LangDetectException"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2779aaf4",
   "metadata": {},
   "source": [
    "## Create lyric corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bad5234",
   "metadata": {},
   "outputs": [],
   "source": [
    "songs = pd.read_csv('/home/sumedhshah94/w266_project_topmusichits/data/interim/songs_charts_new_2000s.csv')\n",
    "hit_songs = songs[songs.hit==1]\n",
    "lyrics_corpus = []\n",
    "for index, row in hit_songs.iterrows():\n",
    "    if not row['lyrics']:\n",
    "        continue\n",
    "    else:\n",
    "        lyrics_corpus.append(row['lyrics'])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738d46bc",
   "metadata": {},
   "source": [
    "## Lyrics Tokenization & Token Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "acdc0304",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = \"([a-zA-Z]+(?:'[a-z]+)?)\"\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "#english = list(set(nltk.corpus.words.words()))\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "def clean_docs_lemma(lyrics_list):\n",
    "    cleaned = []\n",
    "    \n",
    "    # Lyric tokenizataion\n",
    "    for lyric in lyrics_list:\n",
    "        clean_lyric = tokenizer.tokenize(lyric.lower())\n",
    "        cleaned.append(clean_lyric) #lowercase words\n",
    "        \n",
    "    # Lemmatize lyrics\n",
    "    for s,song in enumerate(cleaned):\n",
    "        lemmatized_tokens = []\n",
    "        for token in song:\n",
    "            lemmatized_tokens.append(lemmatizer.lemmatize(token))\n",
    "        cleaned[s] = lemmatized_tokens\n",
    "\n",
    "        \n",
    "    return cleaned\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "00861656",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmed_lyrics = clean_docs_lemma(lyrics_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed40cbf",
   "metadata": {},
   "source": [
    "## Remove stop words and profanities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cbf52d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1608it [00:03, 495.12it/s]\n"
     ]
    }
   ],
   "source": [
    "# Remove Stop Words and Profanities\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "new_stop_words = ['ooh','yeah','hey','whoa','woah', 'ohh', 'was', 'mmm', 'oooh','yah','yeh','mmm', 'hmm','deh','doh','jah','wa']\n",
    "stop_words.extend(new_stop_words)\n",
    "\n",
    "for s,song in tqdm(enumerate(lemmed_lyrics)):\n",
    "    filtered_text = []    \n",
    "    for token in song:\n",
    "        if token not in stop_words:\n",
    "            filtered_text.append(token)\n",
    "    lemmed_lyrics[s] = filtered_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7206da",
   "metadata": {},
   "outputs": [],
   "source": [
    "## STILL NEED TO REMOVE PROFANITIES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d71b17",
   "metadata": {},
   "source": [
    "## Dictionary creation and occurrence-based Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d2e94250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique tokens:  312\n"
     ]
    }
   ],
   "source": [
    "# Dictionary Creation and Filtering\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "dictionary = Dictionary(lemmed_lyrics)\n",
    "dictionary.filter_extremes(no_below = 100, no_above = 0.8)\n",
    "print('Number of unique tokens:', len(dictionary))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854590a4",
   "metadata": {},
   "source": [
    "## Bag-of-Words and Index to Dictionary Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fe3d8988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BOW and Index to Dictionary Conversion\n",
    "from gensim.corpora import MmCorpus\n",
    "\n",
    "gensim_corpus = [dictionary.doc2bow(song) for song in lemmed_lyrics]\n",
    "\n",
    "#create index to dictionary\n",
    "temp = dictionary[0]  # \"loads\" the dictionary\n",
    "id2word = dictionary.id2token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4889b3e",
   "metadata": {},
   "source": [
    "## Set model parameters and execute model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d0ca16bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sumedhshah94/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# Set Model Parameters\n",
    "# training parameters\n",
    "chunksize = 1608\n",
    "passes = 2\n",
    "#iterations = 400\n",
    "num_topics = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8cf3e8e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sumedhshah94/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# Execute Training\n",
    "from gensim.models import LdaModel\n",
    "lda_model = LdaModel(\n",
    "corpus=gensim_corpus,\n",
    "id2word=id2word,\n",
    "chunksize=chunksize,\n",
    "alpha='auto',\n",
    "eta='auto',\n",
    "#iterations=iterations,\n",
    "num_topics=num_topics,\n",
    "passes=passes\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ace5dac",
   "metadata": {},
   "source": [
    "## Display & Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f4b348fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sumedhshah94/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.037*\"one\" + 0.034*\"know\" + 0.022*\"got\" + 0.021*\"time\" + 0.019*\"baby\" + 0.018*\"girl\" + 0.015*\"gonna\" + 0.015*\"like\" + 0.015*\"run\" + 0.014*\"go\"'),\n",
       " (1,\n",
       "  '0.035*\"know\" + 0.029*\"like\" + 0.029*\"go\" + 0.024*\"got\" + 0.024*\"nigga\" + 0.024*\"bitch\" + 0.022*\"let\" + 0.020*\"back\" + 0.019*\"oh\" + 0.018*\"shit\"'),\n",
       " (2,\n",
       "  '0.070*\"oh\" + 0.046*\"love\" + 0.043*\"like\" + 0.024*\"know\" + 0.017*\"got\" + 0.017*\"let\" + 0.016*\"na\" + 0.016*\"wanna\" + 0.016*\"baby\" + 0.015*\"way\"'),\n",
       " (3,\n",
       "  '0.036*\"get\" + 0.035*\"got\" + 0.028*\"nigga\" + 0.026*\"like\" + 0.016*\"know\" + 0.015*\"bitch\" + 0.014*\"never\" + 0.014*\"let\" + 0.013*\"cause\" + 0.013*\"keep\"'),\n",
       " (4,\n",
       "  '0.036*\"know\" + 0.026*\"baby\" + 0.020*\"uh\" + 0.019*\"take\" + 0.016*\"want\" + 0.016*\"give\" + 0.016*\"tell\" + 0.015*\"never\" + 0.015*\"right\" + 0.015*\"cause\"')]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import pprint\n",
    "lda_model.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b6fafae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sumedhshah94/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n"
     ]
    }
   ],
   "source": [
    "# OPTIONAL: calculate coherence score\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "coherencemodel = CoherenceModel(model=lda_model, texts=gensim_corpus, dictionary=dictionary, coherence='c_v')\n",
    "print(coherencemodel.get_coherence())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7ccf8460",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sumedhshah94/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Only callable can be used as callback",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-79976c3a760c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mgensimvis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlda_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgensim_corpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;31m#pyLDAvis.sklearn.prepare(lda_model, gensim_corpus, dictionary)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#pyLDAvis.enable_notebook()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pyLDAvis/gensim_models.py\u001b[0m in \u001b[0;36mprepare\u001b[0;34m(topic_model, corpus, dictionary, doc_topic_dist, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pyLDAvis/_prepare.py\u001b[0m in \u001b[0;36mprepare\u001b[0;34m(topic_term_dists, doc_topic_dists, doc_lengths, vocab, term_frequency, R, lambda_step, mds, n_jobs, plot_opts, sort_topics)\u001b[0m\n\u001b[1;32m    372\u001b[0m    \u001b[0mdoc_lengths\u001b[0m      \u001b[0;34m=\u001b[0m \u001b[0m_series_with_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'doc_length'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m    \u001b[0mvocab\u001b[0m            \u001b[0;34m=\u001b[0m \u001b[0m_series_with_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'vocab'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m    \u001b[0m_input_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic_term_dists\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc_topic_dists\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterm_frequency\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m    \u001b[0mR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pyLDAvis/_prepare.py\u001b[0m in \u001b[0;36m_input_validate\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_input_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m    \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_input_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValidationError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m' * '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pyLDAvis/_prepare.py\u001b[0m in \u001b[0;36m_input_check\u001b[0;34m(topic_term_dists, doc_topic_dists, doc_lengths, vocab, term_frequency)\u001b[0m\n\u001b[1;32m     50\u001b[0m       \u001b[0merr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Length of term_frequency not equal to the number of terms in the vocabulary (len of vocab).'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m    \u001b[0;32mif\u001b[0m \u001b[0m__num_dist_rows__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic_term_dists\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mttds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m       \u001b[0merr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Not all rows (distributions) in topic_term_dists sum to 1.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pyLDAvis/_prepare.py\u001b[0m in \u001b[0;36m__num_dist_rows__\u001b[0;34m(array, ndigits)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m__num_dist_rows__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndigits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m    \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.999\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36msum\u001b[0;34m(self, axis, skipna, level, numeric_only, min_count, **kwargs)\u001b[0m\n\u001b[1;32m  11069\u001b[0m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11070\u001b[0m         ):\n\u001b[0;32m> 11071\u001b[0;31m             return NDFrame.sum(\n\u001b[0m\u001b[1;32m  11072\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11073\u001b[0m             )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36msum\u001b[0;34m(self, axis, skipna, level, numeric_only, min_count, **kwargs)\u001b[0m\n\u001b[1;32m  10789\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10790\u001b[0m     ):\n\u001b[0;32m> 10791\u001b[0;31m         return self._min_count_stat_function(\n\u001b[0m\u001b[1;32m  10792\u001b[0m             \u001b[0;34m\"sum\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnanops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnansum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10793\u001b[0m         )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_min_count_stat_function\u001b[0;34m(self, name, func, axis, skipna, level, numeric_only, min_count, **kwargs)\u001b[0m\n\u001b[1;32m  10771\u001b[0m                 \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10772\u001b[0m             )\n\u001b[0;32m> 10773\u001b[0;31m         return self._reduce(\n\u001b[0m\u001b[1;32m  10774\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10775\u001b[0m             \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_reduce\u001b[0;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[1;32m   8865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8866\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 8867\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   8868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8869\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mfunc\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m   8815\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8816\u001b[0m             \u001b[0;31m# We only use this in the case that operates on self.values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 8817\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   8818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8819\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mblk_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36m_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                 )\n\u001b[1;32m     71\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m                 \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minvalid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/numpy/core/_ufunc_config.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    434\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m         \u001b[0mseterr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moldstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_Unspecified\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m             \u001b[0mseterrcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moldcall\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/numpy/core/_ufunc_config.py\u001b[0m in \u001b[0;36mseterrcall\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m    303\u001b[0m         if (not hasattr(func, 'write') or\n\u001b[1;32m    304\u001b[0m                 not isinstance(func.write, collections.abc.Callable)):\n\u001b[0;32m--> 305\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Only callable can be used as callback\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m     \u001b[0mpyvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mumath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeterrobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m     \u001b[0mold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgeterrcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Only callable can be used as callback"
     ]
    }
   ],
   "source": [
    "# Visualize LDA model using pyLDAvis\n",
    "#!pip install pyLDAvis\n",
    "from __future__ import print_function\n",
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "\n",
    "\n",
    "gensimvis.prepare(lda_model, gensim_corpus, dictionary)\n",
    "#pyLDAvis.sklearn.prepare(lda_model, gensim_corpus, dictionary)\n",
    "#pyLDAvis.enable_notebook()\n",
    "#pyLDAvis.display(vis_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb555162",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
